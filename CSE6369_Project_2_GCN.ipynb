{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnMycL6FEJsU",
        "outputId": "e60c3e09-fe05-4ed5-b934-85861d4f6b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "78g5bd6aFF2R"
      },
      "outputs": [],
      "source": [
        "!cd /content/drive/MyDrive/6389_Assignment2/6389Project2Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHW9C_epCiw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRxmPg5L5vQq",
        "outputId": "570b2a33-9a39-4503-8c48-71b87502ff49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOjRA7ZiCiw5",
        "outputId": "591183b6-2199-4f3e-e808-ae4cf2f73d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch_sparse\n",
        "!pip install torch_scatter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# # LOAD dataset\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import numpy as np\n",
        "# func_data = [ np.loadtxt(f\"/content/drive/MyDrive/6389_Assignment2/6389Project2Data/{n}{i}/FunctionalConnectivity.txt\") for n in [\"AD\",\"CN\"] for i in range(1,11)]\n",
        "# struct_data = [ np.loadtxt(f\"/content/drive/MyDrive/6389_Assignment2/6389Project2Data/{n}{i}/StructuralConnectivity.txt\") for n in [\"AD\",\"CN\"] for i in range(1,11)]\n",
        "# labels = [ int(n == \"AD\") for n in [\"AD\",\"CN\"] for i in range(1,11)]\n",
        "\n",
        "# func_data = torch.tensor(np.array(func_data), dtype=torch.float32)\n",
        "# struct_data = torch.tensor(np.array(struct_data), dtype=torch.float32)\n",
        "# labels = torch.tensor(np.array(labels), dtype=torch.float32)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# functional_data_train, functional_data_test, labels_train, labels_test = train_test_split(\n",
        "#     func_data, labels, test_size=0.2, random_state=42)\n",
        "# structural_data_train, structural_data_test, _, _ = train_test_split(\n",
        "#     struct_data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "O6LuEX_g0x6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIfjs8U1pIQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(300, 64)  # Input features: 2 (identity matrix), Output features: 16\n",
        "        self.conv2 = GCNConv(64, 16)  # Output features: 1\n",
        "        self.fc = nn.Linear(2400, 2)  # Final fully connected layer for batch_size x 2 label size\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_nodes = 150\n",
        "\n",
        "# Generate fully connected graph edge indices\n",
        "        edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j], dtype=torch.long).t().contiguous()\n",
        "        edge_index=edge_index.to('cpu')\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.reshape(2,2400)\n",
        "        x=self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hvFbeOMjPaHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import Food101\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as image\n",
        "#import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "\n",
        "\n",
        "class Dataset():\n",
        "   def __init__(self,root,split,transform=None):\n",
        "\n",
        "      self.files_adresses_labels=[]\n",
        "      self.transform=transform\n",
        "      self.split=split\n",
        "\n",
        "      for subfolder in os.listdir(root):\n",
        "               if subfolder[:2] =='AD':\n",
        "                    for file in os.listdir(os.path.join(root,subfolder)):\n",
        "                        self.files_adresses_labels.append(((os.path.join(root,subfolder,file).replace(\"\\\\\",\"/\")),1))\n",
        "               else:\n",
        "                    for file in os.listdir(os.path.join(root,subfolder)):\n",
        "                        self.files_adresses_labels.append(((os.path.join(root,subfolder,file).replace(\"\\\\\",\"/\")),0))\n",
        "      self.files_adresses_labels= [[self.files_adresses_labels[i], self.files_adresses_labels[i + 1]] for i in range(0, len(self.files_adresses_labels), 2)]\n",
        "      self.train_files_adresses_labels,self.test_files_adresses_labels=  train_test_split(self.files_adresses_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "   def __len__(self):\n",
        "      if self.split=='train':\n",
        "\n",
        "       return len(self.train_files_adresses_labels)\n",
        "\n",
        "      elif self.split=='test':\n",
        "       return len(self.test_files_adresses_labels)\n",
        "\n",
        "   def __getitem__(self,index):\n",
        "\n",
        "\n",
        "      if self.split=='train':\n",
        "\n",
        "         functional_connectivity = np.loadtxt(self.train_files_adresses_labels[index][0][0])\n",
        "         structural_connectivity = np.loadtxt(self.train_files_adresses_labels[index][1][0])\n",
        "         data = torch.tensor(np.concatenate([functional_connectivity, structural_connectivity], axis=1), dtype=torch.float32)\n",
        "         #adj=functional_connectivity\n",
        "\n",
        "         num_nodes = 150\n",
        "\n",
        "         edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j], dtype=torch.long).t().contiguous()\n",
        "\n",
        "         label= (self.train_files_adresses_labels[index][1][1])\n",
        "\n",
        "\n",
        "      if self.split=='test':\n",
        "\n",
        "         functional_connectivity = np.loadtxt(self.test_files_adresses_labels[index][0][0])\n",
        "         structural_connectivity = np.loadtxt(self.test_files_adresses_labels[index][1][0])\n",
        "         data= torch.tensor(np.concatenate([functional_connectivity, structural_connectivity], axis=1), dtype=torch.float32)\n",
        "\n",
        "         num_nodes = 150\n",
        "\n",
        "# Generate fully connected graph edge indices\n",
        "         edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j], dtype=torch.long).t().contiguous()\n",
        "\n",
        "         label= (self.test_files_adresses_labels[index][1][1])\n",
        "\n",
        "      if self.transform is not None:\n",
        "\n",
        "        img=self.transform(img)\n",
        "      return data, label"
      ],
      "metadata": {
        "id": "tpb1B1GwPaQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from model import GNNModel\n",
        "# from dataset import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import Food101\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.image as image\n",
        "\n",
        "root='/content/drive/MyDrive/6389_Assignment2/6389Project2Data/'\n",
        "\n",
        "\n",
        "train_dataset=Dataset(root,split='train')\n",
        "test_dataset=Dataset(root,split='test')\n",
        "\n",
        "\n",
        "train_loader=DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader=DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "\n",
        "#######################################Hyperparameters######################################\n",
        "\n",
        "learning_rate=0.001\n",
        "device='cpu'\n",
        "number_of_epochs=15\n",
        "\n",
        "\n",
        "#####################################initializing network################################\n",
        "model = GNNModel()\n",
        "\n",
        "model=model.to(device)\n",
        "\n",
        "Loss=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "train_accuracy=[]\n",
        "train_Loss=[]\n",
        "#val_accuracy=[]\n",
        "#val_Loss=[]\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "    num_correct=0\n",
        "    num_tot=0\n",
        "    L=0\n",
        "\n",
        "    #################training\n",
        "\n",
        "\n",
        "    for Input, label in train_loader:\n",
        "\n",
        "        label=label.tolist()\n",
        "        #labels_batch = [0, 1]  # Replace this with your batch of labels\n",
        "        num_classes = 2  # Number of unique classes (0 and 1)\n",
        "\n",
        "\n",
        "        one_hot_encodings = np.eye(num_classes)[label]\n",
        "\n",
        "        one_hot_encodings= torch.tensor(one_hot_encodings)\n",
        "\n",
        "        Input=Input.float()\n",
        "\n",
        "        Input=Input.to(device)\n",
        "\n",
        "        one_hot_encodings= one_hot_encodings.float()\n",
        "        one_hot_encodings= one_hot_encodings.to(device)\n",
        "\n",
        "        output=model(Input)\n",
        "\n",
        "        loss=Loss(output, one_hot_encodings)\n",
        "        #print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
        "        #print('loss', loss)\n",
        "\n",
        "\n",
        "        L=loss.item()+L\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# Convert one-hot labels to class labels\n",
        "\n",
        "        predicted_classes = torch.argmax(output, axis=1)\n",
        "        num_correct= torch.sum(predicted_classes == torch.argmax(one_hot_encodings, axis=1))+num_correct\n",
        "\n",
        "        num_tot= one_hot_encodings.size(0)+num_tot\n",
        "\n",
        "    train_acc=float(num_correct)/float(num_tot)\n",
        "\n",
        "    train_accuracy.append(train_acc)\n",
        "    L=L/len(train_loader)\n",
        "    train_Loss.append(L)\n",
        "\n",
        "def test_accuracy_loss(model, test_loader):\n",
        "\n",
        "    test_accuracy=[]\n",
        "    test_Loss=[]\n",
        "\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    num_tot=0\n",
        "    num_correct=0\n",
        "    test_loss=0\n",
        "    L=0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "     print('\"\"\"\"\"\"\"\"\"\"\"\"\"\"')\n",
        "\n",
        "     for Input, label in test_loader:\n",
        "        label=label.tolist()\n",
        "        #labels_batch = [0, 1]  # Replace this with your batch of labels\n",
        "        num_classes = 2  # Number of unique classes (0 and 1)\n",
        "\n",
        "        one_hot_encodings = np.eye(num_classes)[label]\n",
        "\n",
        "        one_hot_encodings= torch.tensor(one_hot_encodings)\n",
        "\n",
        "        Input=Input.float()\n",
        "\n",
        "        Input=Input.to(device)\n",
        "\n",
        "        one_hot_encodings= one_hot_encodings.float()\n",
        "        one_hot_encodings= one_hot_encodings.to(device)\n",
        "\n",
        "        output=model(Input)\n",
        "\n",
        "        loss=Loss(output, one_hot_encodings)\n",
        "\n",
        "        L=loss.item()+L\n",
        "\n",
        "        predicted_classes = torch.argmax(output, axis=1)\n",
        "        num_correct= torch.sum(predicted_classes == torch.argmax(one_hot_encodings, axis=1))+num_correct\n",
        "\n",
        "        num_tot= one_hot_encodings.size(0)+num_tot\n",
        "\n",
        "    test_acc=float(num_correct)/float(num_tot)\n",
        "\n",
        "    test_accuracy.append(test_acc)\n",
        "    L=L/len(test_loader)\n",
        "    test_Loss.append(L)\n",
        "\n",
        "    return test_Loss, test_accuracy\n",
        "\n",
        "test_acc,test_loss=test_accuracy_loss(model, test_loader)\n",
        "\n",
        "print('train_acc= ', train_accuracy)\n",
        "print('train_Loss= ', train_Loss)\n",
        "#print('val_accuracy= ', val_accuracy)\n",
        "#print('val_Loss= ', val_Loss)\n",
        "print('test_acc= ', test_acc)\n",
        "print('test_loss= ', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0i7A6_FZll7",
        "outputId": "f9454319-7a20-4cc9-e710-ef489a6280b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
            "train_acc=  [0.3125, 0.6875, 0.8125, 0.8125, 0.8125, 0.8125, 0.75, 0.9375, 0.9375, 0.9375, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "train_Loss=  [24.33430819644127, 1.472511356434552, 0.9403998714811905, 0.9036345324505533, 1.538659080852248, 6.440930874994706, 2.259920280297589, 0.22546506582511583, 0.1001745752143961, 0.25864959504355056, 0.0, 0.0, 1.043080430918053e-07, 1.4901144140821998e-07, 2.45868676529426e-07]\n",
            "test_acc=  [7.500840798020363]\n",
            "test_loss=  [0.5]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}